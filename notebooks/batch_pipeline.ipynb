{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819cc9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3a7d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4b3d8b98414de6872650e6b3795fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "us_airline_sentiment.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8575182169064d24a47c0fbf866f5e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>None</td>\n",
       "      <td>2/24/2015 11:35</td>\n",
       "      <td>None</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2/24/2015 11:15</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>None</td>\n",
       "      <td>2/24/2015 11:15</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>None</td>\n",
       "      <td>2/24/2015 11:15</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>None</td>\n",
       "      <td>2/24/2015 11:14</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  5.703060e+17           neutral                        1.0000   \n",
       "1  5.703010e+17          positive                        0.3486   \n",
       "2  5.703010e+17           neutral                        0.6837   \n",
       "3  5.703010e+17          negative                        1.0000   \n",
       "4  5.703010e+17          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0           None                        NaN  Virgin America     cairdin   \n",
       "1           None                     0.0000  Virgin America    jnardino   \n",
       "2           None                        NaN  Virgin America  yvonnalynn   \n",
       "3     Bad Flight                     0.7033  Virgin America    jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America    jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @VirginAmerica What @dhepburn said.   \n",
       "1              0  @VirginAmerica plus you've added commercials t...   \n",
       "2              0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3              0  @VirginAmerica it's really aggressive to blast...   \n",
       "4              0  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "  tweet_coord    tweet_created tweet_location               user_timezone  \n",
       "0        None  2/24/2015 11:35           None  Eastern Time (US & Canada)  \n",
       "1        None  2/24/2015 11:15           None  Pacific Time (US & Canada)  \n",
       "2        None  2/24/2015 11:15      Lets Play  Central Time (US & Canada)  \n",
       "3        None  2/24/2015 11:15           None  Pacific Time (US & Canada)  \n",
       "4        None  2/24/2015 11:14           None  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('7Xan7der7/us_airline_sentiment')\n",
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7246fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efae02f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14640</td>\n",
       "      <td>14640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>@united thanks</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>9178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text airline_sentiment\n",
       "count            14640             14640\n",
       "unique           14427                 3\n",
       "top     @united thanks          negative\n",
       "freq                 6              9178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text','airline_sentiment']]\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d32161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b155f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14360</td>\n",
       "      <td>14360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>9079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text airline_sentiment\n",
       "count                              14360             14360\n",
       "unique                             14360                 3\n",
       "top     virginamerica what dhepburn said          negative\n",
       "freq                                   1              9079"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = re.sub(r'http+', '', text)\n",
    "    text = re.sub(r'@+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9]', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df = df.dropna(subset=['text'])\n",
    "# df.to_csv('./data/processed/batch_processed.csv', index=False)\n",
    "\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf73e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "aug_synonym = naw.SynonymAug(aug_src='wordnet', aug_min=1, aug_max=3)\n",
    "\n",
    "aug_insert = naw.SynonymAug(aug_src='wordnet', aug_min=1, aug_max=2, aug_p=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbdc6327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUGMENTING MINORITY CLASSES\n",
      "============================================================\n",
      "\n",
      "Augmentation targets:\n",
      "  • Neutral class:  3,043 → 9,079 (need 6,036 more)\n",
      "  • Positive class: 2,238 → 9,079 (need 6,841 more)\n",
      "\n",
      "Augmenting neutral class...\n",
      "   Processed 500/6036...\n",
      "   Processed 1000/6036...\n",
      "   Processed 1500/6036...\n",
      "   Processed 2000/6036...\n",
      "   Processed 2500/6036...\n",
      "   Processed 3000/6036...\n",
      "   Processed 3500/6036...\n",
      "   Processed 4000/6036...\n",
      "   Processed 4500/6036...\n",
      "   Processed 5000/6036...\n",
      "   Processed 5500/6036...\n",
      "   Processed 6000/6036...\n",
      "Neutral class augmented: 6036 new samples\n",
      "\n",
      "Augmenting positive class...\n",
      "   Processed 500/6841...\n",
      "   Processed 1000/6841...\n",
      "   Processed 1500/6841...\n",
      "   Processed 2000/6841...\n",
      "   Processed 2500/6841...\n",
      "   Processed 3000/6841...\n",
      "   Processed 3500/6841...\n",
      "   Processed 4000/6841...\n",
      "   Processed 4500/6841...\n",
      "   Processed 5000/6841...\n",
      "   Processed 5500/6841...\n",
      "   Processed 6000/6841...\n",
      "   Processed 6500/6841...\n",
      "Positive class augmented: 6841 new samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def augment_text(text, augmenter, num_augmentations=1):\n",
    "    augmented_texts = []\n",
    "    for _ in range(num_augmentations):\n",
    "        try:\n",
    "            aug_text = augmenter.augment(text)\n",
    "            if aug_text and aug_text != text:\n",
    "                augmented_texts.append(aug_text)\n",
    "        except:\n",
    "            continue\n",
    "    return augmented_texts\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AUGMENTING MINORITY CLASSES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "negative_df = df[df['airline_sentiment'] == 'negative']\n",
    "neutral_df = df[df['airline_sentiment'] == 'neutral']\n",
    "positive_df = df[df['airline_sentiment'] == 'positive']\n",
    "\n",
    "max_count = len(negative_df)\n",
    "\n",
    "neutral_needed = max_count - len(neutral_df)\n",
    "positive_needed = max_count - len(positive_df)\n",
    "\n",
    "print(f\"\\nAugmentation targets:\")\n",
    "print(f\"  • Neutral class:  {len(neutral_df):,} → {max_count:,} (need {neutral_needed:,} more)\")\n",
    "print(f\"  • Positive class: {len(positive_df):,} → {max_count:,} (need {positive_needed:,} more)\")\n",
    "\n",
    "augmented_data = []\n",
    "\n",
    "print(f\"\\nAugmenting neutral class...\")\n",
    "neutral_samples = neutral_df.sample(n=neutral_needed, replace=True, random_state=42)\n",
    "for idx, row in enumerate(neutral_samples.itertuples(), 1):\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"   Processed {idx}/{neutral_needed}...\")\n",
    "    \n",
    "    augmenter = aug_synonym if idx % 2 == 0 else aug_insert\n",
    "    aug_texts = augment_text(row.text, augmenter, num_augmentations=1)\n",
    "    \n",
    "    if aug_texts:\n",
    "        augmented_data.append({\n",
    "            'airline_sentiment': row.airline_sentiment,\n",
    "            'text': aug_texts[0]\n",
    "        })\n",
    "\n",
    "print(f\"Neutral class augmented: {len([d for d in augmented_data if d['airline_sentiment'] == 'neutral'])} new samples\")\n",
    "\n",
    "print(f\"\\nAugmenting positive class...\")\n",
    "positive_samples = positive_df.sample(n=positive_needed, replace=True, random_state=42)\n",
    "for idx, row in enumerate(positive_samples.itertuples(), 1):\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"   Processed {idx}/{positive_needed}...\")\n",
    "    \n",
    "    augmenter = aug_synonym if idx % 2 == 0 else aug_insert\n",
    "    aug_texts = augment_text(row.text, augmenter, num_augmentations=1)\n",
    "    \n",
    "    if aug_texts:\n",
    "        augmented_data.append({\n",
    "            'airline_sentiment': row.airline_sentiment,\n",
    "            'text': aug_texts[0]\n",
    "        })\n",
    "\n",
    "print(f\"Positive class augmented: {len([d for d in augmented_data if d['airline_sentiment'] == 'positive'])} new samples\")\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1927aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df, augmented_df], ignore_index=True)\n",
    "\n",
    "df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851531ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27237</td>\n",
       "      <td>27237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26348</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[southwestair thanks]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>9079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text airline_sentiment\n",
       "count                   27237             27237\n",
       "unique                  26348                 3\n",
       "top     [southwestair thanks]          negative\n",
       "freq                        9              9079"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335f1c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(897)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_csv('./data/processed/dataframe_balanced.csv', index=False)\n",
    "df = pd.read_csv('./data/processed/dataframe_balanced.csv')\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7cf3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab815c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9079\n",
       "neutral     8753\n",
       "positive    8508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661d1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = df[df['airline_sentiment'] == 'negative']\n",
    "neu_df = df[df['airline_sentiment'] == 'neutral']\n",
    "pos_df = df[df['airline_sentiment'] == 'positive']\n",
    "\n",
    "neg_df_reduced = neg_df.sample(\n",
    "    n=len(pos_df),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df = pd.concat(\n",
    "    [neg_df_reduced, neu_df, pos_df],\n",
    "    ignore_index=True\n",
    ").sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0d00cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "neutral     8753\n",
       "negative    8508\n",
       "positive    8508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895cd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: ed465b38-0f70-43ab-b2e4-af21c6b31fcf)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "No sentence-transformers model found with name cardiffnlp/twitter-roberta-base-sentiment. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e8d26b8df7493da853e3183c82cbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ede566fb9641ce9f7ac5d0ea0d81d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7ec2f9cf764062957c249d6bb476c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a765f57b74fffae5786134bee0c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0554071452d44249856c9a3d3cd845b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c04b92dac5409c9ff328bd278a84cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35969cc57ac43ae9fbb81ecebe97521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/806 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# embed_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "embed_model = SentenceTransformer('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "embeddings = embed_model.encode(df['text'], show_progress_bar=True, convert_to_numpy=True,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b9bcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united we would   how do i contact you to disc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['united any chance you are allowing reflight ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['united if you d love to see more girls be in...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usairways what does  your reservation is  out ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jetblue if there s a schedule change on my tix...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0  united we would   how do i contact you to disc...          negative\n",
       "1  ['united any chance you are allowing reflight ...           neutral\n",
       "2  ['united if you d love to see more girls be in...           neutral\n",
       "3  usairways what does  your reservation is  out ...          negative\n",
       "4  jetblue if there s a schedule change on my tix...           neutral"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53a3612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6160055e-01, -5.9598249e-01,  1.2330471e-01, ...,\n",
       "        -8.7793320e-01,  8.6030159e-03, -2.4165902e-01],\n",
       "       [-1.7571187e-01, -8.7361604e-01,  1.8219958e-01, ...,\n",
       "        -1.7844989e+00, -2.8510524e-02, -2.9796681e-01],\n",
       "       [ 5.2962351e-01,  4.5887071e-01, -2.6892433e-01, ...,\n",
       "        -5.0736237e-01, -3.2030919e-01,  9.7607052e-01],\n",
       "       ...,\n",
       "       [-9.3582802e-04, -6.7999470e-01, -8.8480771e-02, ...,\n",
       "        -1.5023693e+00, -4.1139656e-01,  2.6550552e-01],\n",
       "       [-2.7207145e-02, -2.4444950e-01, -1.1655974e-01, ...,\n",
       "        -1.7925044e+00, -4.1917968e-01,  5.5006921e-01],\n",
       "       [ 1.3636443e-01,  1.0526717e+00, -3.9309824e-01, ...,\n",
       "         9.4752079e-01, -5.2063471e-01,  1.6376647e+00]],\n",
       "      shape=(25769, 768), dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25efcd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted batch 1/6\n",
      "Inserted batch 2/6\n",
      "Inserted batch 3/6\n",
      "Inserted batch 4/6\n",
      "Inserted batch 5/6\n",
      "Inserted batch 6/6\n",
      "\n",
      "Stored 25769 vectors successfully in ChromaDB\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"aerostream_reviews\",\n",
    "    \n",
    ")\n",
    "\n",
    "documents = df[\"text\"].astype(str).tolist()\n",
    "\n",
    "metadatas = [\n",
    "    {\n",
    "        \"review_id\": int(i),\n",
    "        \"airline_sentiment\": row[\"airline_sentiment\"]\n",
    "    }\n",
    "    for i, row in df.reset_index().iterrows()\n",
    "]\n",
    "\n",
    "ids = [str(i) for i in range(len(documents))]\n",
    "\n",
    "BATCH_SIZE = 5000\n",
    "num_batches = math.ceil(len(ids) / BATCH_SIZE)\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start = batch_idx * BATCH_SIZE\n",
    "    end = start + BATCH_SIZE\n",
    "\n",
    "    collection.add(\n",
    "        ids=ids[start:end],\n",
    "        embeddings=embeddings[start:end].tolist(),\n",
    "        documents=documents[start:end],\n",
    "        metadatas=metadatas[start:end],\n",
    "    )\n",
    "\n",
    "    print(f\"Inserted batch {batch_idx + 1}/{num_batches}\")\n",
    "\n",
    "print(f\"\\nStored {len(ids)} vectors successfully in ChromaDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e12251eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report , f1_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "all_items = collection.get(include=['embeddings','metadatas','documents'])\n",
    "X = embeddings  \n",
    "y = df['airline_sentiment'].values\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, df.index, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "def evaluate_model(name , model):\n",
    "    print(f\"=== {name} ===\") \n",
    "\n",
    "    train_acc = model.score(X_train, y_train) \n",
    "    test_pred = model.predict(X_test) \n",
    "    test_acc = accuracy_score(y_test, test_pred) \n",
    "    \n",
    "    f1 = f1_score(y_test, test_pred, average=\"macro\") \n",
    "\n",
    "    print(\"Train accuracy:\", train_acc) \n",
    "    print(\"Test accuracy :\", test_acc) \n",
    "    print(\"F1-score :\", f1) \n",
    "    print(\"Gap:\", train_acc - test_acc) \n",
    "    print(classification_report(y_test, test_pred)) \n",
    "\n",
    "    print(confusion_matrix(y_test, test_pred) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7476fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== logreg ===\n",
      "Train accuracy: 0.876546204220228\n",
      "Test accuracy : 0.8608847497089639\n",
      "F1-score : 0.8612000462226422\n",
      "Gap: 0.015661454511264106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90      1702\n",
      "     neutral       0.82      0.82      0.82      1751\n",
      "    positive       0.86      0.86      0.86      1701\n",
      "\n",
      "    accuracy                           0.86      5154\n",
      "   macro avg       0.86      0.86      0.86      5154\n",
      "weighted avg       0.86      0.86      0.86      5154\n",
      "\n",
      "[[1535  117   50]\n",
      " [ 137 1433  181]\n",
      " [  40  192 1469]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logreg = OneVsRestClassifier(LogisticRegression(max_iter=3000))\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "evaluate_model(\"logreg\", logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "823b7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== svm ===\n",
      "Train accuracy: 0.8769827795294688\n",
      "Test accuracy : 0.8608847497089639\n",
      "F1-score : 0.8611714936204287\n",
      "Gap: 0.0160980298205049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90      1702\n",
      "     neutral       0.82      0.82      0.82      1751\n",
      "    positive       0.87      0.86      0.87      1701\n",
      "\n",
      "    accuracy                           0.86      5154\n",
      "   macro avg       0.86      0.86      0.86      5154\n",
      "weighted avg       0.86      0.86      0.86      5154\n",
      "\n",
      "[[1538  117   47]\n",
      " [ 144 1432  175]\n",
      " [  41  193 1467]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "base_svm = LinearSVC(C=0.3,max_iter=3000, random_state=42)\n",
    "svm = CalibratedClassifierCV(base_svm, method=\"sigmoid\", cv=5)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "evaluate_model(\"svm\", svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b502001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== rf ===\n",
      "Train accuracy: 0.9999029832646131\n",
      "Test accuracy : 0.8554520760574311\n",
      "F1-score : 0.8560525647583437\n",
      "Gap: 0.144450907207182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88      1702\n",
      "     neutral       0.81      0.84      0.83      1751\n",
      "    positive       0.86      0.87      0.87      1701\n",
      "\n",
      "    accuracy                           0.86      5154\n",
      "   macro avg       0.86      0.86      0.86      5154\n",
      "weighted avg       0.86      0.86      0.86      5154\n",
      "\n",
      "[[1456  161   85]\n",
      " [ 125 1474  152]\n",
      " [  42  180 1479]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(\"rf\", rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dd7bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved best\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(svm, './models/svm_sentiment_model.pkl')\n",
    "print('Model Saved best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pred = svm.predict(X_test) \n",
    "\n",
    "    \n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, test_pred),\n",
    "    \"f1-score\": f1_score(y_test, test_pred, average=\"macro\"),\n",
    "    \"report\": classification_report(y_test, test_pred, output_dict=True)\n",
    "}\n",
    "\n",
    "joblib.dump(metrics, \"./models/svm_metrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da506f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "y_train_bin = label_binarize(y_train, classes=classes)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "svm = OneVsRestClassifier(LinearSVC(max_iter=3000))\n",
    "svm.fit(X_train, y_train_bin)\n",
    "\n",
    "y_score = svm.decision_function(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for LinearSVC (One-vs-Rest)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
